{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default stuff (display width, dir change, jupyter extentions)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import os\n",
    "os.chdir('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anodeclstmgru.constants as const\n",
    "import os\n",
    "from anodeclstmgru.models.lit_module import AutoEncoderLitModule\n",
    "from anodeclstmgru.data.data_module import SWaTSDataModule\n",
    "from anodeclstmgru.data.dataset import SWaTSDataset\n",
    "import yaml\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493239e5",
   "metadata": {},
   "source": [
    "# Load model and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c94da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = 14\n",
    "TEST_SET_STEP_SIZE = 10\n",
    "hparams_path = f'./lightning_logs/version_{MODEL_VERSION}/hparams.yaml'\n",
    "with open(hparams_path, 'r') as stream:\n",
    "        hparam_dct = yaml.safe_load(stream)\n",
    "hparam_dct.update(dict(test_set_step_size=TEST_SET_STEP_SIZE))\n",
    "ckpt_file_name = os.listdir(f'./lightning_logs/version_{MODEL_VERSION}/checkpoints/')[0]\n",
    "ckpt_file_path = f'./lightning_logs/version_{MODEL_VERSION}/checkpoints/{ckpt_file_name}'\n",
    "model = AutoEncoderLitModule.load_from_checkpoint(ckpt_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874d23c",
   "metadata": {},
   "source": [
    "# Load training samples and predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce09964",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_dct.pop('test_set_step_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = SWaTSDataModule(**hparam_dct)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.test_set_step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f788ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = dm.train_dataloader()\n",
    "batch_in = iter(train_data_loader).next()\n",
    "batch_out = model(batch_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774053fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_out = model(batch_in)\n",
    "df_out = pd.DataFrame(batch_out[0,:,:].detach().numpy(), columns=const.SENSOR_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs(idx):\n",
    "    df_in = pd.DataFrame(batch_in[idx,:,:].numpy(), columns=const.SENSOR_COLS)\n",
    "    df_out = pd.DataFrame(batch_out[idx,:,:].detach().numpy(), columns=const.SENSOR_COLS)\n",
    "    return df_in, df_out\n",
    "\n",
    "\n",
    "def plot_ts_and_reconstruction(signal='AIT203', training_sample_idx=0):\n",
    "    df_in, df_out = get_dfs(training_sample_idx)\n",
    "    fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "    for df, key in zip([df_in, df_out], ['orig.', 'reconstr.']):\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[signal], name=f'{signal}_{key}'), row=1, col=1)\n",
    "    title = f'{signal} original and reproduction over time (Sample {training_sample_idx} of first training batch).'\n",
    "    fig.update_layout(height=600, width=800, title_text=title)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "interact(plot_ts_and_reconstruction, signal=const.SENSOR_COLS, training_sample_idx=list(range(32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78619fcb",
   "metadata": {},
   "source": [
    "# Alright, now what about the reconstruction error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55761fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(idx, input_array):\n",
    "    out = model(torch.tensor(input_array[idx,:,:].reshape(-1, input_array.shape[1], input_array.shape[2]))).detach().numpy()[0,:,:]\n",
    "    return mean_squared_error(input_array[idx,:,:], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ada36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run first time\n",
    "mse_list = [get_mse(i, dm.swats_test.samples)\n",
    "            for i in tqdm(list(range(dm.swats_test.samples.shape[0])))]\n",
    "timestamps = dm.swats_test.timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions\n",
    "# only run first time\n",
    "df_errors = pd.DataFrame(dict(mse=mse_list, timestamp=timestamps))\n",
    "store = pd.HDFStore(const.HDF_STORE_PATH_PREPROC)\n",
    "store[f'df_errors_{MODEL_VERSION}'] = df_errors\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e998b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "store = pd.HDFStore(const.HDF_STORE_PATH_PREPROC)\n",
    "df_errors = store[f'df_errors_{MODEL_VERSION}']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d181c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_plot(threshold=1):\n",
    "    # load data frames from h5 store\n",
    "    store = pd.HDFStore(const.HDF_STORE_PATH_INTERIM)\n",
    "    df_labels = store['df_labels']\n",
    "    store.close()\n",
    "    # filter labels df to the attack that have a end date attached\n",
    "    # transofrm end time to full timestmap\n",
    "    df_labels_time = df_labels[df_labels['End Time'].notna()].copy()\n",
    "    df_labels_time.loc[:, 'End Time'] = [datetime.combine(datetime.date(a), b) for a,b in zip(\n",
    "        df_labels_time['Start Time'], df_labels_time['End Time'])]\n",
    "    df_labels_time = df_labels_time.reset_index(drop=True)\n",
    "    # ok, lets remove everything smaller than min_date and larger than max date...\n",
    "    df_labels_time = df_labels_time[(df_labels_time['Start Time'] > const.MIN_DATE) &\n",
    "                             (df_labels_time['Start Time'] < const.MAX_DATE)]\n",
    "    df_plot_label = df_labels_time.copy()\n",
    "    \n",
    "    df_errors['anomaly_predicted'] = [x > threshold for x in df_errors.mse]\n",
    "    fig = make_subplots(rows=3, cols=1, shared_xaxes=True)\n",
    "    fig.add_trace(go.Scatter(x=df_errors.timestamp, y=df_errors.mse, name='mse'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df_errors.timestamp, y=df_errors.anomaly_predicted,\n",
    "                             name='Anomaly predicted'), row=2, col=1)\n",
    "    for i in range(len(df_plot_label)):\n",
    "        df_plot_label = df_plot_label.reset_index(drop=True)\n",
    "        start = df_plot_label.loc[i, 'Start Time']\n",
    "        end = df_plot_label.loc[i, 'End Time']\n",
    "        attack = df_plot_label.loc[i, 'Attack #']\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[start, end],\n",
    "                       y=[1, 1], name=f'Attack #{attack}'),\n",
    "            row=3, col=1,\n",
    "        )\n",
    "    title = f'MSE, anomaly predictions and real anomalies over time. Sample window size: {300*10/60} min'\n",
    "    fig.update_layout(title_text=title)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(create_results_plot, threshold=np.linspace(0,2,89))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86291c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(create_results_plot, threshold=np.linspace(0,2,89))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8b636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
